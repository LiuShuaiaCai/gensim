## 语料库和词向量 - Corpus and Vector Spaces

#### 可以先设置一下日志的格式
```python
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
```

### 1、从字符串到向量 - From Strings to Vectors
从表示为字符串的文档开始,下面是一个文档列表组成的小型语料库：
```python
documents  =  [ "实验室abc计算机应用程序的人机界面",
              "用户对计算机系统响应时间的意见调查",
              "EPS用户界面管理系统",
              "EPS系统与人体系统工程测试",
              "用户感知响应时间与误差测量的关系",
              "随机二进制无序树的生成",
              "树中路径的交叉图",
              "图未成年人IV树的宽度和井准排序",
              "图未成年人调查" ]
```
接下来，对文档进行标记，删除常用的词语以及仅在语料库中出现一次的词语
```python
import jieba
from pprint import pprint

# 停用词
stoplists = set('的 与 和'.split())
# 将语料库分词
texts = [ [ word for word in jieba.lcut(document) if word not in stoplists ] for document in documents ]
# 统计词频
from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for word in text:
        frequency[word] += 1
# 删除只出现一次的词语
texts = [ [ token for token in text if frequency[token] > 1 ] for text in texts ]
pprint(texts)

# 结果如下
[['实验室'],
 ['用户', '响应', '时间'],
 ['实验室', 'EPS'],
 ['实验室', 'EPS'],
 ['用户', '响应', '时间'],
 ['树'],
 ['图'],
 ['图', '未成年人', '树'],
 ['图', '未成年人']]
```




### 2、语料库流 - 一次一个文档

### 3、语料库格式

#### 4、与 Numpy 和 SciPy 的兼容性