## 语料库和词向量 - Corpus and Vector Spaces

#### 可以先设置一下日志的格式
```python
import logging
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
```

### 1、从字符串到向量 - From Strings to Vectors
从表示为字符串的文档开始,下面是一个文档列表组成的小型语料库：
```python
documents  =  [ "实验室abc计算机应用程序的人机界面",
              "用户对计算机系统响应时间的意见调查",
              "实验室的EPS用户界面管理系统",
              "实验室的EPS系统与人体系统工程测试",
              "用户感知响应时间与误差测量的关系",
              "随机二进制无序树的生成",
              "树中路径的交叉图",
              "图未成年人IV树的宽度和井准排序",
              "图未成年人调查" ]
```
接下来，对文档进行标记，删除常用的词语以及仅在语料库中出现一次的词语
```python
import jieba
from pprint import pprint

# 停用词
stoplists = set('的 与 和'.split())
# 将语料库分词
texts = [ [ word for word in jieba.lcut(document) if word not in stoplists ] for document in documents ]
# 统计词频
from collections import defaultdict
frequency = defaultdict(int)
for text in texts:
    for word in text:
        frequency[word] += 1
# 删除只出现一次的词语
texts = [ [ token for token in text if frequency[token] > 1 ] for text in texts ]
pprint(texts)

# 结果如下
[['实验室'],
 ['用户', '响应', '时间'],
 ['实验室', 'EPS'],
 ['实验室', 'EPS'],
 ['用户', '响应', '时间'],
 ['树'],
 ['图'],
 ['图', '未成年人', '树'],
 ['图', '未成年人']]
```
将文档转化为向量，我们将使用 [词袋](https://en.wikipedia.org/wiki/Bag-of-words_model) 的文档表示。
> 将字典保存为文件，以便以后可以很好的应用，不用每次都要转化
```python
# 将语料转化为字典
from gensim import corpora
dictionary = corpora.Dictionary(texts)
# 保存字典
dictionary.save('corpus.dict')
```
在这里，我们为语料库中出现的所有单词分配了一个唯一的整数id gensim.corpora.dictionary.Dictionary。这会扫描文本，收集字数和相关统计数据。最后，我们看到在处理过的语料库中有12个不同的单词，这意味着每个文档将由12个数字表示（即，通过12-D向量）。要查看单词及其ID之间的映射：
```python
# 加载字典模型
dictionary = corpora.Dictionary.load('corpus.dict')
# 查看单词及其ID之间的映射
mapping = dictionary.token2id
pprint(mapping)

# 结果如下
{'EPS': 4, '响应': 1, '图': 6, '实验室': 0, '时间': 2, '未成年人': 7, '树': 5, '用户': 3}
```

将标记化文档实际转换为向量：
> 我们先看一个小栗子
```python
new_doc = "实验室用户"
new_vec = dictionary.doc2bow(jieba.lcut(new_doc))
pprint(new_vec)
# 结果如下
[(0, 1), (3, 1)]
```

    注：函数doc2bow()只计算每个不同单词的出现次数，将单词转换为整数单词id，并将结果作为稀疏向量返回


### 2、语料库流 - 一次一个文档

### 3、语料库格式

#### 4、与 Numpy 和 SciPy 的兼容性